{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering: k-means and linkage-based clustering\n",
    "\n",
    "In this notebook we are going to practice with the k-means and the linkage-based (called \"agglomerative\" in scikit learn) clustering algorithms.\n",
    "\n",
    "In particular you are going to implement the k-means algorithm from scratch and to compare the results with the implementation already present in the sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "# If a package is missing in your setup, install it with 'conda install <package_name>' \n",
    "# or with 'pip install <package_name>'\n",
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import imageio as imio\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_sample_image\n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D #3d plotting functions\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "\n",
    "from copy import deepcopy  #deepcopy ensures that a copy of all the object data is performed (not just the pointers)\n",
    "\n",
    "print ('scikit-learn version: ', sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "    \n",
    "Place your ID number in the ID variable, it will be used as random seed (as usual the random seed can affect a little bit the results, try to change it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix your ID (\"numero di matricola\") and the seed for random generator\n",
    "ID =   1232236\n",
    "np.random.seed(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the provided images and display them (if you like you can experiment with other images)\n",
    "image1 = imio.imread('data/santaclaus2.jpg')\n",
    "image2  = imio.imread(\"data/landscape.jpg\")\n",
    "image3  = imio.imread(\"data/reindeer.jpg\")\n",
    "\n",
    "ax = plt.axes(xticks=[], yticks=[])\n",
    "ax.imshow(image1)\n",
    "plt.show()\n",
    "print(\"Santa Claus image: \",image1.shape)\n",
    "\n",
    "ax2 = plt.axes(xticks=[], yticks=[])\n",
    "ax2.imshow(image2)\n",
    "plt.show()\n",
    "print(\"Landscape image: \",image2.shape)\n",
    "\n",
    "ax3 = plt.axes(xticks=[], yticks=[])\n",
    "ax3.imshow(image3)\n",
    "plt.show()\n",
    "print(\"Reindeer image: \",image3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start by using the Santa Claus image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the data to a matrix of num_pixels x 3 \n",
    "# (divide by 255 to have colors in [0 1] range for plotting functions of sklearn)\n",
    "data = image1.reshape(image1.shape[0]*image1.shape[1], 3)/255\n",
    "new_img = data.reshape(image1.shape)\n",
    "\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the points in the 3-dimensional space with normalized intervals between 0 and 1\n",
    "# (corresponding to the three channels of the image, i.e. Red Green and Blue)\n",
    "\n",
    "fig = pyplot.figure()\n",
    "axis = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "r, g, b = list(data[:,0]), list(data[:,1]), list(data[:,2])\n",
    "\n",
    "axis.scatter(r, g, b, c=data, s=5, marker=\"o\")\n",
    "axis.set_xlabel(\"Red\")\n",
    "axis.set_ylabel(\"Green\")\n",
    "axis.set_zlabel(\"Blue\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 1\n",
    "Implement the k-means algorithm manually (**do not use the kmeans function of sklearn and do not download implementations from other web sources**). The inputs to the function is the set of vectors to be clustered and the number of clusters. The output must contain the clusters barycenters, a vector associating each data point to the corresponding cluster and the error (value of the cost function) at each iteration.\n",
    "Additionally, fix a maximum number of iterations of the k-means algorithm (e.g., 50).\n",
    "\n",
    "Be careful about the initalization, you can use some random points from the training set, or get random values but ensure they are in the proper range. Poor initalizations can lead to the failure of the algorithm (in particular check that no cluster is initialized as empty, otherwise the algorithm can not update it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x,y):\n",
    "    return math.sqrt(sum([(x[i]-y[i])**2 for i in range(len(x))]))\n",
    "\n",
    "max_iters=50\n",
    "\n",
    "def my_kmeans(points, k):\n",
    "    n = 0\n",
    "\n",
    "    points = pd.DataFrame(points,columns=['r','g','b'])\n",
    "    \n",
    "    # Initialization\n",
    "    centroids = np.random.random((k,3))\n",
    "    old_centroids = np.zeros((k,3))\n",
    "    error = [0]*max_iters\n",
    "    clusters = 0\n",
    "    \n",
    "    # Update rule\n",
    "    while n < max_iters:\n",
    "        \n",
    "        cost = 0\n",
    "        \n",
    "        for cl in range(k):                \n",
    "                points[cl]=((points['r']-centroids[cl][0])**2+(points['g']-centroids[cl][1])**2+(points['b']-centroids[cl][2])**2).pow(1./2)\n",
    "        \n",
    "        points['cluster'] = points[[c for c in range(k)]].idxmin(axis=1)\n",
    "        \n",
    "        # Recalculating centroids\n",
    "        for cl in range(k):\n",
    "            centroids[cl] = points.loc[points['cluster']==cl,['r','g','b']].mean()\n",
    "\n",
    "        # Computing cost function\n",
    "        conditions = [points['cluster']==cl for cl in range(k)]\n",
    "        choices = [points[cl] for cl in range(k)]\n",
    "        points['cost'] = np.select(conditions, choices)\n",
    "        points['cost'] = points['cost'].pow(2)\n",
    "        cost = sum(points['cost'])\n",
    "        error[n-1] = cost\n",
    "        \n",
    "        # Convergence check\n",
    "        if np.array_equal(centroids, old_centroids): \n",
    "            print('Convergence reached with ', n, ' iterations')\n",
    "            break\n",
    "        old_centroids = centroids.copy()\n",
    "        \n",
    "        n+=1\n",
    "    \n",
    "    clusters = points['cluster']\n",
    "    \n",
    "    return centroids, clusters, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 2:\n",
    "\n",
    "Now try the function you developed on the Santa Claus image with three clusters (k=3). \n",
    "\n",
    "Then plot the data points in the 3-dimensional space, each point must be coloured based on the membership to one of the clusters. Additionally, plot the respective clusters centroids (use a different shape, size or color to highlight the centroids)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mykmeans_centers,clusters,error =  my_kmeans(data,3)\n",
    "\n",
    "print('Centroids:')\n",
    "print(mykmeans_centers)\n",
    "\n",
    "fig = pyplot.figure()\n",
    "axis = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "axis.set_xlabel(\"Red\")\n",
    "axis.set_ylabel(\"Green\")\n",
    "axis.set_zlabel(\"Blue\")\n",
    "axis.scatter(r, g, b, marker=\"o\", c=clusters, s=1, cmap='viridis', zorder=0, alpha=0.5 )\n",
    "axis.scatter(mykmeans_centers[:,0], mykmeans_centers[:,1], mykmeans_centers[:,2], c='black', s=400, zorder=10)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen by executing several times the cell above, the final result strongly depends on the initial (random) centroids. So it can be useful to repeat the execution to be more sure about the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 3: \n",
    "Plot the value of the error versus the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1,1,figsize=(8,8))\n",
    "ax.set_xlabel('Number of iterations')\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Variation of the cost function')\n",
    "ax.plot(np.arange(len(error)),error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 4:\n",
    "Now use the k-means function provided in sklearn. Pass to the function the number of clusters and use multiple random initializations (n_init parameter). Go to the documentation page for further details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans =  KMeans(n_clusters=3,init='random')\n",
    "kmeans.fit(data)\n",
    "print(kmeans.cluster_centers_)\n",
    "print(kmeans.labels_)\n",
    "print(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 5:\n",
    "Perform the same plot as above but with the output of the k-means function provided in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax1 = plt.figure(figsize=(8,8)).add_subplot(1,1,1,projection='3d')\n",
    "\n",
    "# RGB plot\n",
    "ax1.set_xlabel(\"Red\")\n",
    "ax1.set_ylabel(\"Green\")\n",
    "ax1.set_zlabel(\"Blue\")\n",
    "ax1.set_title(\"Cluster with sklearn\")\n",
    "ax1.scatter(r, g, b, marker=\"o\", c=kmeans.labels_, s=1, cmap='viridis', zorder=0, alpha=0.5 )\n",
    "ax1.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], kmeans.cluster_centers_[:,2], c='black', s=400, zorder=10)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: \n",
    "\n",
    "Compare the results obtained with your implementation and with k-means from sklearn. Do you observe any differences, i.e., do the two plots match? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots obtained are almost equivalent, and also the numeric values of the centroids are very similar to each other, sign of the fact that the manual algorithm has been implemented correctly. Also repeating the execution of the algorithm we keep obtaining the same results. Looking at the behaviour of the cost function we find what we were expecting: the error decrease after each iteration until the complete convergence. <br>\n",
    "Something that is interesting to notice is that, even the algorithm find alway the same centroids, the color to which they are associated depends on the initial values randomly sampled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 6:\n",
    "\n",
    "Now display the segmented image based on the 3 clusters found above with both the k-means functions by sklearn and your k-means implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(18,6))\n",
    "\n",
    "ax1.imshow(image1)\n",
    "ax1.set_title('Original Image')\n",
    "\n",
    "# SK learn \n",
    "sk_clustered_santa = kmeans.cluster_centers_[kmeans.labels_]\n",
    "sk_clustered_santa = sk_clustered_santa.reshape(image1.shape)\n",
    "ax2.imshow(sk_clustered_santa)\n",
    "ax2.set_title('SK learn - clustering')\n",
    "\n",
    "# Personal implementation\n",
    "ps_clustered_santa = mykmeans_centers[clusters]\n",
    "ps_clustered_santa = sk_clustered_santa.reshape(image1.shape)\n",
    "ax3.imshow(ps_clustered_santa)\n",
    "ax3.set_title('Personal - clustering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: \n",
    "\n",
    "What do you observe? Do you think clustering is useful for image segmenation? And for image compression?  Comment your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I observe an image that is decomposed into its base 3 colors (red, white and green). I think that clustering is useful for image segmentation since it allow us to highlight image contours (at least when these are well defined). Its usage for image compression, instead, depends on the image itself, in particular if we can still recognize it after the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 8:\n",
    "\n",
    "Now load the landscape image (optional: try also with the reindeer image) and segment it using kmeans with k varying from 2 to 15 clusters. You can use the sklearn implementation.\n",
    "\n",
    "Then plot the resulting data points in the 3-dimensional space, each point must be colored based on the cluster membership. \n",
    "Additionally, plot the respective clusters centroids.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image2    # LANDSCAPE\n",
    "#image = image3    # REINDEER\n",
    "data = image.reshape(image.shape[0]*image.shape[1], 3) / 255\n",
    "print(data.shape)\n",
    "r, g, b = list(data[:,0]), list(data[:,1]), list(data[:,2])\n",
    "errors = [0]*14\n",
    "\n",
    "for k in range(2,16):\n",
    "    kmeans =  KMeans(n_clusters=k,init='random')\n",
    "    kmeans.fit(data)\n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    ax1 = fig.add_subplot(1,2,1,projection=\"3d\")\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax1.set_xlabel(\"Red\")\n",
    "    ax1.set_ylabel(\"Green\")\n",
    "    ax1.set_zlabel(\"Blue\")\n",
    "    ax1.set_title(\"Cluster with sklearn\")\n",
    "    ax1.scatter(r, g, b, marker=\"o\", c=kmeans.labels_, s=1, cmap='viridis', zorder=0, alpha=0.5 )\n",
    "    ax1.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], kmeans.cluster_centers_[:,2], c='black', s=400, zorder=10)\n",
    "    errors[k-2] = kmeans.inertia_\n",
    "    \n",
    "    # Clustered image\n",
    "    clustered_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "    clustered_image = clustered_image.reshape(image.shape)\n",
    "    ax2.imshow(clustered_image)\n",
    "    ax2.set_title('Clustered image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 9:\n",
    "\n",
    "Plot for different values of k (e.g. k between 2 and 15) the respective error of the kmeans algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1,1,figsize=(8,8))\n",
    "ax.set_xlabel('Number of clusters')\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Variation of the cost function respect to the number of clusters')\n",
    "ax.plot(np.arange(len(errors)),errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Question 3:\n",
    "\n",
    "Compare the results with different values of k, what do you observe? \n",
    "\n",
    "Analyze also the error, which one do you think is the optimal value of k ?\n",
    "\n",
    "Is there a single, clear answer ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the plot, the error decrease at the increasing of the number of clusters used in the process: this was predictable, since we are using each time a more precise analysis instrument. I think that there isn't an optimal value of k, since, due to overfitting, the biggest is k, the smallest will be the error. <br>\n",
    "The \"perfect\" value of k is the number of the pixel of the image: in that case we would have the maximum precision possible. But in that case we would get a dendogram, that is useless for our pourpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linkage-based clustering\n",
    "\n",
    "The second part of the assignment concern instead linkage-based clustering. We will use the AgglomerativeClustering module of sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Load sample data\n",
    "data = np.load('data/moon_data.npz')\n",
    "print(data.files)\n",
    "X = data['X']\n",
    "labels_true = data['labels_true']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 10: \n",
    "\n",
    "Now exploit the AgglomerativeClustering algorithm on the provided sample data points. Use the \"single\" linkage type that correspond to the minimum distance criteria seen in the lectures and 2 clusters. Notice that the \"single\" option has been introduced recently in sklearn, if you get an error ensure you have a recent version of the library. Plot the resulting clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Compute Agglomerative Clustering\n",
    "\n",
    "# Standarize features\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "db = AgglomerativeClustering(n_clusters=2,linkage=\"single\")\n",
    "db.fit(X_std) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot result\n",
    "\n",
    "fig = pyplot.figure(figsize=(15,6))\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection=\"3d\")\n",
    "r, g, b = list(X[:,0]), list(X[:,1]), list(labels_true)\n",
    "\n",
    "ax1.scatter(r, g, b, c=labels_true, s=5, marker=\"o\")\n",
    "ax1.set_xlabel(\"Red\")\n",
    "ax1.set_ylabel(\"Green\")\n",
    "ax1.set_zlabel(\"Blue\")\n",
    "ax1.set_title(\"Original RGB image\")\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection=\"3d\")\n",
    "ax2.scatter(r, g, b, marker=\"o\", c=db.labels_, s=1, cmap='viridis', zorder=0, alpha=0.5 )\n",
    "ax2.set_xlabel(\"Red\")\n",
    "ax2.set_ylabel(\"Green\")\n",
    "ax2.set_zlabel(\"Blue\")\n",
    "ax2.set_title(\"Clustered RGB image\")\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 11: \n",
    "\n",
    "Now try the KMeans with two clusters on the same dataset we used for the AgglomerativeClustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans =  KMeans(n_clusters=2,init='random')\n",
    "kmeans.fit(X_std)\n",
    "\n",
    "ax = plt.figure(figsize=(8,8)).add_subplot(1,1,1,projection='3d')\n",
    "\n",
    "# RGB plot\n",
    "ax.set_xlabel(\"Red\")\n",
    "ax.set_ylabel(\"Green\")\n",
    "ax.set_zlabel(\"Blue\")\n",
    "ax.set_title(\"Cluster with sklearn\")\n",
    "ax.scatter(r, g, b, marker=\"o\", c=kmeans.labels_, s=1, cmap='viridis', zorder=0, alpha=0.5 )\n",
    "ax.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], c='black', s=400, zorder=10)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "\n",
    "Compare the results of K-means and Agglomerative Clustering and explain what you observe and why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There is an obvious distance between the two methods: while agglomerative clustering group the points in a way that is visibly \"more correct\", the k means algorithm seems to \"act\" better in the vertical dimension, since it divide the points into two clusters basing on their relative distances and don't taking into account the fact that they are located into different plains. This phenomenon is due to the research of a spherycal n-dimensional symmetry that the k-means wants to find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
